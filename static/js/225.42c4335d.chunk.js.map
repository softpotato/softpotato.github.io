{"version":3,"file":"static/js/225.42c4335d.chunk.js","mappings":"mBAgBA,MAAMA,EAUFC,WAAAA,CAAYC,EAAKC,EAAOC,EAAOC,EAAOC,EAAOC,GACzCC,KAAKN,IAAMA,EACXM,KAAKL,MAAQA,EACbK,KAAKJ,MAAQA,EACbI,KAAKH,MAAQA,EACbG,KAAKF,MAAQA,EACbE,KAAKD,MAAQA,CACjB,EAwDW,MAAME,EAMjBR,WAAAA,GAA2B,IAAfS,EAAOC,UAAAC,OAAA,QAAAC,IAAAF,UAAA,GAAAA,UAAA,GAAG,GAGlB,MAAMG,EAAiB,IAAId,EAAQ,KAAM,MACnCe,EAAe,IAAIf,EAAQ,KAAM,MACvCc,EAAeT,MAAQU,EACvBA,EAAaX,MAAQU,EAGrBN,KAAKE,QAAUA,EAAU,EAAIA,EAAU,GACvCF,KAAKQ,KAAO,EACZR,KAAKS,MAAQC,MAAMR,GAASS,KAAK,MACjCX,KAAKY,MAAQN,EACbN,KAAKa,IAAMN,EAGX,IAAK,IAAIO,EAAI,EAAGA,EAAId,KAAKS,MAAML,OAAQU,IACnCd,KAAKS,MAAMK,GAAK,IAAItB,EAAQ,KAAM,KAG1C,CASAuB,MAAAA,CAAOrB,EAAKC,GACR,GAAW,MAAPD,GAAwB,MAATC,EAAe,OAGlC,IAAIqB,EAAOhB,KAAKS,MAAMT,KAAKiB,kBAAkBvB,EAAIwB,WAEjD,KAAqB,MAAdF,EAAKjB,OAIR,GAHAiB,EAAOA,EAAKjB,MAGRiB,EAAKtB,IAAIyB,OAAOzB,GAIhB,YADAM,KAAKoB,oBAAoBJ,GAMjC,MAAMK,EAAU,IAAI7B,EAAQE,EAAKC,GAGjCqB,EAAKjB,MAAQsB,EACbA,EAAQvB,MAAQkB,EAGhBhB,KAAKsB,oBAAoBD,EAC7B,CAQAD,mBAAAA,CAAoBJ,GAGM,MAAlBA,EAAKpB,MAAMF,MACXsB,EAAKnB,MAAMD,MAAQoB,EAAKpB,MACxBoB,EAAKpB,MAAMC,MAAQmB,EAAKnB,MACxBmB,EAAKnB,MAAQG,KAAKY,MAAMf,MACxBmB,EAAKpB,MAAQI,KAAKY,MAClBZ,KAAKY,MAAMf,MAAMD,MAAQoB,EACzBhB,KAAKY,MAAMf,MAAQmB,EAG3B,CAUAM,mBAAAA,CAAoBN,GAYhB,GATAhB,KAAKQ,OAGLQ,EAAKnB,MAAQG,KAAKY,MAAMf,MACxBmB,EAAKpB,MAAQI,KAAKY,MAClBZ,KAAKY,MAAMf,MAAMD,MAAQoB,EACzBhB,KAAKY,MAAMf,MAAQmB,EAGfhB,KAAKQ,KAAOR,KAAKE,QAAS,CAC1BF,KAAKQ,OAGL,MAAMe,EAAWvB,KAAKa,IAAIjB,MAG1B2B,EAAS3B,MAAMC,MAAQ0B,EAAS1B,MAChC0B,EAAS1B,MAAMD,MAAQ2B,EAAS3B,MAGhC2B,EAASzB,MAAMC,MAAQwB,EAASxB,MACV,MAAlBwB,EAASxB,QACTwB,EAASxB,MAAMD,MAAQyB,EAASzB,MAGxC,CAEJ,CAQA0B,GAAAA,CAAI9B,GACA,GAAW,MAAPA,EACA,OAAO,EAGX,IAAIsB,EAAOhB,KAAKS,MAAMT,KAAKiB,kBAAkBvB,EAAIwB,WACjD,KAAqB,MAAdF,EAAKjB,OAGR,GAFAiB,EAAOA,EAAKjB,MAERiB,EAAKtB,IAAIyB,OAAOzB,GAChB,OAAO,EAIf,OAAmB,MAAZsB,EAAKtB,KAAcA,EAAIyB,OAAOH,EAAKtB,IAC9C,CASA+B,QAAAA,CAAS/B,GAEL,GAAW,MAAPA,EACA,OAAO,KAGX,IAAIsB,EAAOhB,KAAKS,MAAMT,KAAKiB,kBAAkBvB,EAAIwB,WAEjD,KAAqB,MAAdF,EAAKjB,OAGR,GAFAiB,EAAOA,EAAKjB,MAERiB,EAAKtB,IAAIyB,OAAOzB,GAEhB,OADAM,KAAKoB,oBAAoBJ,GAClBA,EAAKrB,MAGpB,OAAO,IACX,CAUAsB,iBAAAA,CAAkBC,GACd,OAAOA,EAAWlB,KAAKE,OAC3B,ECrQJ,MAAMwB,EAAgB,CAClB,UAAa,SAAUC,GAA0C,IAAvCC,IAASzB,UAAAC,OAAA,QAAAC,IAAAF,UAAA,KAAAA,UAAA,GAAS0B,EAAO1B,UAAAC,OAAA,QAAAC,IAAAF,UAAA,GAAAA,UAAA,GAAG,SAQlD,MAAgB,KAAZ0B,GACAF,EAAEG,MAAK,SAAUC,EAAGC,GAiDhB,MAAMC,EAAOP,EAAcQ,eAAeL,EAASE,GAGnD,OAFaL,EAAcQ,eAAeL,EAASG,GAErCC,CAGlB,IACON,IAIPA,EAAEG,MAAK,SAAUC,EAAGC,GAChB,MAAMG,EAAQC,KAAKC,MAAMN,EAAEO,SACrBC,EAAQH,KAAKC,MAAML,EAAEM,SAE3B,OAAIH,EAAQI,GACA,GAAKX,EAAY,GAAK,GACvBW,EAAQJ,EACR,GAAKP,EAAY,GAAK,GAEtB,CAEf,IAEOD,EAEf,EACA,MAAS,SAAUA,GAA0C,IAAvCC,IAASzB,UAAAC,OAAA,QAAAC,IAAAF,UAAA,KAAAA,UAAA,GAK3B,OAJAwB,EAAEG,MAAK,SAAUC,EAAGC,GAChB,OAAOD,EAAES,MAAMC,cAAcT,EAAEQ,QAAUZ,EAAY,GAAK,EAC9D,IAEOD,CACX,EACA,WAAc,SAAUA,GAA0C,IAAvCC,IAASzB,UAAAC,OAAA,QAAAC,IAAAF,UAAA,KAAAA,UAAA,GAchC,OAbAwB,EAAEG,MAAK,SAAUC,EAAGC,GAChB,MAAMG,EAAQC,KAAKC,MAAMN,EAAEO,SACrBC,EAAQH,KAAKC,MAAML,EAAEM,SAE3B,OAAIH,EAAQI,GACA,GAAKX,EAAY,GAAK,GACvBW,EAAQJ,EACR,GAAKP,EAAY,GAAK,GAEtB,CAEf,IAEOD,CACX,EACA,WAAc,SAAUA,GAA0C,IAAvCC,IAASzB,UAAAC,OAAA,QAAAC,IAAAF,UAAA,KAAAA,UAAA,GAchC,OAbAwB,EAAEG,MAAK,SAAUC,EAAGC,GAChB,MAAMG,EAAQC,KAAKC,MAAMN,EAAEW,SACrBH,EAAQH,KAAKC,MAAML,EAAEU,SAE3B,OAAIP,EAAQI,GACA,GAAKX,EAAY,GAAK,GACvBW,EAAQJ,EACR,GAAKP,EAAY,GAAK,GAEtB,CAEf,IAEOD,CACX,EACAO,eAAgB,SAAUS,EAAWC,GAMjC,MAAMC,EAAkB,IAAIC,OAAOH,EAAUI,QAAQ,MAAO,KAAM,MAClE,IAAIC,EAAM,EAGVA,KAASJ,EAAkB,OAAK,IAAIK,MAAMJ,IAAoB,IAAIzC,OAElE4C,KAASJ,EAAwB,aAAK,IAAIK,MAAMJ,IAAoB,IAAIzC,OAGxE,IAAK,IAAI8C,KAASN,EAAWO,MAAO,CAChC,MAAMC,EAAcR,EAAWO,MAAMD,GAErCF,GAAOhD,KAAKqD,gBAAgBR,EAAiBO,EACjD,CAEA,OAAOJ,CAEX,EACAK,eAAAA,CAAgBC,EAAUF,GACtB,GAAmB,MAAfA,EACA,OAAO,EAGX,IAAIG,EAAQ,EAMZ,GAJIC,OAAOC,OAAOL,EAAa,aAC3BG,KAAWH,EAAqB,SAAK,IAAIH,MAAMK,IAAa,IAAIlD,QAGhEoD,OAAOC,OAAOL,EAAa,YAC3B,IAAK,IAAIM,KAAgBN,EAAsB,SAC3CG,GAASvD,KAAKqD,gBAAgBC,EAAUI,GAIhD,OAAOH,CACX,GAiEW,MAAMI,EASjBlE,WAAAA,CAAYmE,GAER5D,KAAK6D,gBAAkBD,EAOvB5D,KAAK8D,WAAaN,OAAOO,OAAO,MAChC/D,KAAKgE,UAAYR,OAAOO,OAAO,MAC/B/D,KAAKiE,0BAA4BT,OAAOO,OAAO,MAC/C/D,KAAKkE,wBAA0BV,OAAOO,OAAO,MAC7C/D,KAAKmE,eAAiBX,OAAOO,OAAO,MAGpC/D,KAAK8D,WAAqB,SAAI,GAC9B9D,KAAK8D,WAAoB,QAAI,GAC7B9D,KAAK8D,WAAiB,KAAI,GAC1B9D,KAAK8D,WAAkB,MAAI,GAC3B9D,KAAKkE,wBAAmC,UAAI,GAC5ClE,KAAKkE,wBAAiC,QAAI,GAC1ClE,KAAKkE,wBAAwB,eAAiB,GAC9ClE,KAAKkE,wBAAmC,UAAI,GAC5ClE,KAAKkE,wBAAgC,OAAI,GACzClE,KAAKmE,eAAwB,QAAI,GAGjC,IAAK,IAAIzE,KAAOkE,EAAa,CACzB,MAAMQ,EAAMR,EAAYlE,GAGlB2E,EAAQD,EAAIE,KAAKC,cACnBF,KAASrE,KAAK8D,WACd9D,KAAK8D,WAAWO,GAAOG,KAAK9E,GAE5BM,KAAK8D,WAAWO,GAAS,CAAC3E,GAI9B,IAAK,IAAIwD,KAASkB,EAAIK,KAAM,CACxB,MAAMC,EAAON,EAAIK,KAAKvB,GAAOqB,cAEzBG,KAAQ1E,KAAKgE,UACbhE,KAAKgE,UAAUU,GAAMF,KAAK9E,GAE1BM,KAAKgE,UAAUU,GAAQ,CAAChF,EAEhC,CAGA,IAAK,IAAIwD,KAASkB,EAAIO,sBAAuB,CACzC,MAAMC,EAAQR,EAAIO,sBAAsBzB,GAAOqB,cAE3CK,KAAS5E,KAAKiE,0BACdjE,KAAKiE,0BAA0BW,GAAOJ,KAAK9E,GAE3CM,KAAKiE,0BAA0BW,GAAS,CAAClF,EAEjD,CAGA,MAAMmF,EAAOT,EAAIU,OAAOP,cACpBM,KAAQ7E,KAAKkE,wBACblE,KAAKkE,wBAAwBW,GAAML,KAAK9E,GAExCM,KAAKkE,wBAAwBW,GAAQ,CAACnF,GAI1C,MAAMqF,EAAQX,EAAIY,SAAST,cACvBQ,KAAS/E,KAAKmE,eACdnE,KAAKmE,eAAeY,GAAOP,KAAK9E,GAEhCM,KAAKmE,eAAeY,GAAS,CAACrF,EAGtC,CAYA,IAAK,IAAIA,KAAOM,KAAK8D,WACjB9D,KAAK8D,WAAWpE,GAAKoC,OAGzB,IAAK,IAAIpC,KAAOM,KAAKgE,UACjBhE,KAAKgE,UAAUtE,GAAKoC,OAGxB,IAAK,IAAIpC,KAAOM,KAAKiE,0BACjBjE,KAAKiE,0BAA0BvE,GAAKoC,OAGxC,IAAK,IAAIpC,KAAOM,KAAKkE,wBACjBlE,KAAKkE,wBAAwBxE,GAAKoC,OAGtC,IAAK,IAAIpC,KAAOM,KAAKmE,eACjBnE,KAAKmE,eAAezE,GAAKoC,OAI7B9B,KAAKiF,kBAAoB,IAAIhF,EAAS,GAU1C,CAeAiF,OAAAA,GAGI,MAAO,CACH,IAAI1B,OAAO2B,KAAKnF,KAAK8D,aACrB,IAAIN,OAAO2B,KAAKnF,KAAKgE,YACrB,IAAIR,OAAO2B,KAAKnF,KAAKiE,4BACrB,IAAIT,OAAO2B,KAAKnF,KAAKkE,0BACrB,IAAIV,OAAO2B,KAAKnF,KAAKmE,iBAE7B,CAaAiB,MAAAA,CAAOC,GAiBH,IAAIC,EAAkBtF,KAAKiF,kBAAkBxD,SAAS4D,EAAaE,eAG5C,MAAnBD,GAEAA,EAAkBtF,KAAKwF,yBAAyBH,EAAaE,eAC7DvF,KAAKiF,kBAAkBlE,OAAOsE,EAAaE,cAAe,IAAID,KAE9DA,EAAkB,IAAIA,GAQ1B,IAAK,IAAIxE,EAAI,EAAGA,EAAIwE,EAAgBlF,OAAQU,IACxCwE,EAAgBxE,GAAKd,KAAK6D,gBAAgByB,EAAgBxE,IAwB1D0C,OAAOC,OAAO/B,EAAe2D,EAAaI,QAC1C/D,EAAc2D,EAAaI,QAAQH,EAAiBD,EAAazD,UAAWyD,EAAaxD,UAGzF6D,QAAQC,MAAM,2DACdjE,EAA0B,WAAE4D,EAAiBD,EAAazD,UAAWyD,EAAaxD,UAyCtF,IAAI+D,EAAsB,GAG1B,GAA6B,KAAzBP,EAAaxD,QACb,IAAK,IAAIqB,KAASoC,EAAiB,CAC/B,MAAMO,EAAOP,EAAgBpC,GACzBxB,EAAcQ,eAAemD,EAAaxD,QAASgE,IAAS,GAC5DD,EAAoBpB,KAAKqB,EAEjC,MAEAD,EAAsBN,EAI1B,OAAOM,CAEX,CAqBAE,sBAAAA,CAAuBC,GACnB,IAAIC,EAAM,EACV,IAAK,IAAIC,EAAM,EAAGA,EAAMF,EAAM3F,OAAQ6F,IAClC,IAAK,IAAIC,EAAS,EAAGA,EAASH,EAAME,GAAK7F,OAAQ8F,IAC7CF,IAGR,OAAOA,CACX,CAoBAR,wBAAAA,CAAyBW,GAmBrB,IAAIC,EAAiB,GAGrB,IAAK,IAAIlD,KAASiD,EAAcE,MAAM,GAAI,CACtC,MAAMC,EAAUH,EAAcE,MAAM,GAAGnD,GAGnCoD,KAAWtG,KAAK8D,YAChBsC,EAAe5B,KAAKxE,KAAK8D,WAAWwC,GAE5C,CAIA,IAAK,IAAIpD,KAASiD,EAAcE,MAAM,GAAI,CACtC,MAAME,EAASJ,EAAcE,MAAM,GAAGnD,GAClCqD,KAAUvG,KAAKgE,WACfoC,EAAe5B,KAAKxE,KAAKgE,UAAUuC,GAE3C,CAGA,IAAK,IAAIrD,KAASiD,EAAcE,MAAM,GAAI,CACtC,MAAMG,EAAQL,EAAcE,MAAM,GAAGnD,GACjCsD,KAASxG,KAAKiE,2BACdmC,EAAe5B,KAAKxE,KAAKiE,0BAA0BuC,GAE3D,CAGA,IAAK,IAAItD,KAASiD,EAAcE,MAAM,GAAI,CACtC,MAAMI,EAAQN,EAAcE,MAAM,GAAGnD,GACjCuD,KAASzG,KAAKkE,yBACdkC,EAAe5B,KAAKxE,KAAKkE,wBAAwBuC,GAEzD,CAGA,IAAK,IAAIvD,KAASiD,EAAcE,MAAM,GAAI,CACtC,MAAMK,EAAQP,EAAcE,MAAM,GAAGnD,GACjCwD,KAAS1G,KAAKmE,gBACdiC,EAAe5B,KAAKxE,KAAKmE,eAAeuC,GAEhD,CAGA,IAAIC,EAAmB,KAInBA,EADqD,IAArD3G,KAAK8F,uBAAuBK,EAAcE,OACvB7C,OAAO2B,KAAKnF,KAAK6D,iBAG7BsC,EAAcS,KACF5G,KAAK6G,qBAAqBT,GAI1BpG,KAAK8G,cAAcV,GAI1CA,EAAiB,GAGjB,IAAK,IAAIlD,KAASiD,EAAcY,MAAM,GAAI,CACtC,MAAMT,EAAUH,EAAcY,MAAM,GAAG7D,GACnCoD,KAAWtG,KAAK8D,YAChBsC,EAAe5B,KAAKxE,KAAK8D,WAAWwC,GAE5C,CAIA,IAAK,IAAIpD,KAASiD,EAAcY,MAAM,GAAI,CACtC,MAAMR,EAASJ,EAAcY,MAAM,GAAG7D,GAClCqD,KAAUvG,KAAKgE,WACfoC,EAAe5B,KAAKxE,KAAKgE,UAAUuC,GAE3C,CAGA,IAAK,IAAIrD,KAASiD,EAAcY,MAAM,GAAI,CACtC,MAAMP,EAAQL,EAAcY,MAAM,GAAG7D,GACjCsD,KAASxG,KAAKiE,2BACdmC,EAAe5B,KAAKxE,KAAKiE,0BAA0BuC,GAE3D,CAGA,IAAK,IAAItD,KAASiD,EAAcY,MAAM,GAAI,CACtC,MAAMN,EAAQN,EAAcY,MAAM,GAAG7D,GACjCuD,KAASzG,KAAKkE,yBACdkC,EAAe5B,KAAKxE,KAAKkE,wBAAwBuC,GAEzD,CAGA,IAAK,IAAIvD,KAASiD,EAAcY,MAAM,GAAI,CACtC,MAAML,EAAQP,EAAcY,MAAM,GAAG7D,GACjCwD,KAAS1G,KAAKmE,gBACdiC,EAAe5B,KAAKxE,KAAKmE,eAAeuC,GAEhD,CAGA,IAAIM,EAAmB,KAGnBA,EADAb,EAAcc,KACKjH,KAAK6G,qBAAqBT,GAE1BpG,KAAK8G,cAAcV,GAQ1C,MAAMc,EAAa,GAEnB,IAAIC,EAAO,EACPC,EAAO,EACX,KAAOD,EAAOR,EAAiBvG,QAAUgH,EAAOJ,EAAiB5G,SAES,IAAlEuG,EAAiBQ,GAAM1E,cAAcuE,EAAiBI,KACtDF,EAAW1C,KAAKmC,EAAiBQ,IACjCA,MAEwE,IAAjER,EAAiBQ,GAAM1E,cAAcuE,EAAiBI,KAI7DD,IAHAC,KAUR,KAAOD,EAAOR,EAAiBvG,QAC3B8G,EAAW1C,KAAKmC,EAAiBQ,IACjCA,IAGJ,OAAOD,CACX,CAmBAJ,aAAAA,CAAcO,GACV,OAAuB,IAAnBA,EAAQjH,OACDiH,EAGJA,EAAQC,QAAO,CAACC,EAAMC,KACzB,MAAMC,EAAS,GACf,IAAI3G,EAAI,EACJ4G,EAAI,EAER,KAAO5G,EAAIyG,EAAKnH,QAAUsH,EAAIF,EAAKpH,SAGS,IAApCmH,EAAKzG,GAAG2B,cAAc+E,EAAKE,KAC3BD,EAAOjD,KAAK+C,EAAKzG,IACjBA,KAE0C,IAAnCyG,EAAKzG,GAAG2B,cAAc+E,EAAKE,KAClCD,EAAOjD,KAAKgD,EAAKE,IACjBA,MAGAD,EAAOjD,KAAKgD,EAAK1G,IACjBA,IACA4G,KAKR,KAAO5G,EAAIyG,EAAKnH,QACZqH,EAAOjD,KAAK+C,EAAKzG,IACjBA,IAGJ,KAAO4G,EAAIH,EAAKnH,QACZqH,EAAOjD,KAAKgD,EAAKE,IACjBA,IAGJ,OAAOD,CAAM,GAIrB,CAEAZ,oBAAAA,CAAqBQ,GACjB,OAAuB,IAAnBA,EAAQjH,OACD,GAGJiH,EAAQC,QAAO,CAACC,EAAMC,KACzB,MAAMC,EAAS,GACf,IAAI3G,EAAI,EACJ4G,EAAI,EAER,KAAO5G,EAAIyG,EAAKnH,QAAUsH,EAAIF,EAAKpH,SAES,IAApCmH,EAAKzG,GAAG2B,cAAc+E,EAAKE,IAC3B5G,IAE0C,IAAnCyG,EAAKzG,GAAG2B,cAAc+E,EAAKE,IAClCA,KAGAD,EAAOjD,KAAK+C,EAAKzG,IACjBA,GAAK,EACL4G,GAAK,GAKb,OAAOD,CAAM,GAErB,EC/zBW,MAAME,EACjBlI,WAAAA,GACIO,KAAKkB,SAAW,CACpB,CAEAC,MAAAA,CAAOyG,GACH,OAAa,MAATA,GAIG5H,KAAKkB,WAAa0G,EAAM1G,QACnC,ECKG,MAAM2G,EAAS,SAAUC,GAAgB,IAAXC,EAAI5H,UAAAC,OAAA,QAAAC,IAAAF,UAAA,GAAAA,UAAA,GAAG,EACpC6H,EAAK,WAAaD,EAAME,EAAK,WAAaF,EAC9C,IAAK,IAAWG,EAAPpH,EAAI,EAAOA,EAAIgH,EAAI1H,OAAQU,IAChCoH,EAAKJ,EAAIK,WAAWrH,GACpBkH,EAAKI,KAAKC,KAAKL,EAAKE,EAAI,YACxBD,EAAKG,KAAKC,KAAKJ,EAAKC,EAAI,YAI5B,OAFAF,EAAKI,KAAKC,KAAKL,EAAMA,IAAO,GAAK,YAAcI,KAAKC,KAAKJ,EAAMA,IAAO,GAAK,YAC3EA,EAAKG,KAAKC,KAAKJ,EAAMA,IAAO,GAAK,YAAcG,KAAKC,KAAKL,EAAMA,IAAO,GAAK,YACpE,YAAc,QAAUC,IAAOD,IAAO,EACjD,EAYaM,EAA2B,SAAUvC,GAC9C,IAAIwC,EAAO,EACX,IAAK,IAAIrF,KAAS6C,EAAO,CACrB,MAAMyC,EAAMzC,EAAM7C,GAClBqF,GAAcV,EAAOW,EACzB,CACA,OAAOD,CACX,EAWaE,EAAyB,SAAU1C,GAC5C,MAAM2C,EAAkBC,KAAKC,UAAU7C,GACvC,OAAO8B,EAAOa,EAClB,EC5Be,MAAMG,UAAsBlB,EAUvClI,WAAAA,CAAYqJ,EAAeC,EAAcC,EAAeC,GACpDC,QAGAlJ,KAAKqG,MAAQyC,EACb9I,KAAK4G,KAAOmC,EACZ/I,KAAK+G,MAAQiC,EACbhJ,KAAKiH,KAAOgC,EAKZjJ,KAAKkB,SAAWuH,EACZ,CACIzI,KAAKqG,MAAM8C,KAAKC,GAASd,EAAyBc,KAAO9B,QAAO,CAAC+B,EAAKC,IAAiBD,EAAIC,IAC3FtJ,KAAK4G,KAAO,IAAM,IAClB5G,KAAK+G,MAAMoC,KAAKC,GAASd,EAAyBc,KAAO9B,QAAO,CAAC+B,EAAKC,IAAiBD,EAAIC,IAC3FtJ,KAAKiH,KAAO,IAAM,KAM9B,CAMA9F,MAAAA,CAAOoI,GAGH,OAA0B,MAAtBA,IAKAA,EAAmBrI,WAAalB,KAAKkB,WAKpClB,KAAK4G,OAAS2C,EAAmB3C,MAAU5G,KAAKiH,OAASsC,EAAmBtC,OAK7EjH,KAAKqG,MAAMjG,SAAWmJ,EAAmBlD,MAAMjG,QAAUJ,KAAK+G,MAAM3G,SAAWmJ,EAAmBxC,MAAM3G,WAKvGyI,EAAcW,sBAAsBxJ,KAAKqG,MAAOkD,EAAmBlD,UAKnEwC,EAAcW,sBAAsBxJ,KAAK+G,MAAOwC,EAAmBxC,UAM5E,CAeA,4BAAOyC,CAAsBC,EAAMC,GAC/B,MAAMC,EAAc,IAAIC,IAGxB,IAAK,IAAI1G,KAASuG,EAAM,CACpB,MAAMI,EAAWJ,EAAKvG,GAChB4G,EAAUxB,EAAyBuB,GAKrCF,EAAYnI,IAAIsI,GAChBH,EAAYI,IAAID,GAAStF,KAAKqF,GAE9BF,EAAYK,IAAIF,EAAS,CAACD,GAElC,CAGA,IAAK,IAAI3G,KAASwG,EAAM,CACpB,MAAMO,EAAYP,EAAKxG,GACjB4G,EAAUxB,EAAyB2B,GAEzC,IAAKN,EAAYnI,IAAIsI,GACjB,OAAO,EAMX,IAAII,GAAa,EACjB,IAAK,IAAIC,KAAYR,EAAYI,IAAID,GACjC,GAAIjB,EAAcuB,qBAAqBH,EAAWE,GAAW,CACzDD,GAAa,EACb,KACJ,CAGJ,IAAKA,EACD,OAAO,CAEf,CAEA,OAAO,CAEX,CAeA,2BAAOE,CAAqBX,EAAMC,GAG9B,GAAID,EAAKrJ,SAAWsJ,EAAKtJ,OACrB,OAAO,EAGX,MAAMiK,EAAU,IAAIC,IAEpB,IAAK,IAAIC,KAASd,EACdY,EAAQG,IAAID,GAGhB,IAAK,IAAIA,KAASb,EACd,IAAKW,EAAQ7I,IAAI+I,GACb,OAAO,EAIf,OAAO,CACX,CAEA,QAAIE,GACA,MAAMC,EAAY,GACZC,EAAY,GAElB,IAAK,IAAIC,KAAS5K,KAAKqG,MACnBqE,EAAUlG,KAAK,IAAIoG,IAGvB,IAAK,IAAIA,KAAS5K,KAAK+G,MACnB4D,EAAUnG,KAAK,IAAIoG,IAGvB,OAAO,IAAI/B,EAAc6B,EAAW1K,KAAK+I,aAAc4B,EAAW3K,KAAKiJ,aAC3E,EC3MW,MAAM4B,UAAoBlD,EAYrClI,WAAAA,CAAYoC,EAAS4D,EAAQ7D,EAAWkH,EAAeC,EAAcC,EAAeC,GAChFC,QAGAlJ,KAAK6B,QAAUA,EACf7B,KAAKyF,OAASA,EACdzF,KAAK4B,UAAYA,EAGjB5B,KAAKuF,cAAgB,IAAIsD,EAAcC,EAAeC,EAAcC,EAAeC,GAGnFjJ,KAAKkB,SAAWuH,EAAuB,CAACzI,KAAK6B,QAAS7B,KAAKyF,OAAQzF,KAAK4B,UAAY,IAAM,IAAK5B,KAAKuF,cAAcrE,UACtH,CAEAC,MAAAA,CAAO2J,GACH,OAAwB,MAApBA,GACApF,QAAQC,MAAM,oBACP,GAIP3F,KAAKkB,WAAa4J,EAAiB5J,WAKnClB,KAAK6B,UAAYiJ,EAAiBjJ,UAKlC7B,KAAKyF,SAAWqF,EAAiBrF,SAKjCzF,KAAK4B,YAAckJ,EAAiBlJ,WAKjC5B,KAAKuF,cAAcpE,OAAO2J,EAAiBC,qBAEtD,CAeA,wBAAOC,CAAkBC,GACrB,OAAO,IAAIJ,EACPI,EAAUpJ,QACVoJ,EAAUxF,OACVwF,EAAUrJ,UACVqJ,EAAU1F,cAAcc,MACxB4E,EAAU1F,cAAcqB,KACxBqE,EAAU1F,cAAcwB,MACxBkE,EAAU1F,cAAc0B,KAEhC,ECpEJiE,KAAKC,aAAc,EAEnBD,KAAKE,UAAY,KAUjBF,KAAKG,UAAaC,IAOd,GAAKJ,KAAKC,YAaH,CAMH,MAAMI,EAASL,KAAKE,UAAUhG,OAAOyF,EAAYG,kBAAkBM,EAAQE,OAG3EC,YAAY,CAAC/L,IAAK4L,EAAQE,KAAM7L,MAAO4L,GAC3C,MApBIL,KAAKC,aAAc,EAEnBD,KAAKE,UAAY,IAAIzH,EAAY2H,EAAQE,MAGzCC,YAAYP,KAAKE,UAAUlG,UAe/B,C","sources":["state/lru_cache.js","state/post_storage.js","state/lru_key.js","state/utils.js","state/category_group.js","state/search_input.js","worker/search_worker.js"],"sourcesContent":["/**\n * This class stores the data for the LRU Cache class.\n * It has 2 sets of pointers, denoted o for order and\n * h for hashMap. \n * \n * Order is meant for the access order pointers used to\n * maintain order of the nodes last used.\n * \n * HashMap is meant for the custom hash map nodes that\n * it stores it in, since the hash map expects collisions.\n * It uses a doubly linked list to maintain the references.\n * \n * Both systems use a doubly linked list pointer, since we\n * might access the Node by one set of pointers, but we'll\n * need to update both sets if we remove it.\n */\nclass LRUNode {\n    /**\n     * \n     * @param {LRUKey} key      - The key of the LRU Node\n     * @param {Object[]} value  - The value stored in the node\n     * @param {LRUNode} [oPrev] - the prev node in the ordered linked list\n     * @param {LRUNode} [oNext] - the next node in the ordered linked list\n     * @param {LRUNode} [hPrev] - The prev node in the hash map linked list\n     * @param {LRUNode} [hNext] - The next node in the hash map linekd list\n     */\n    constructor(key, value, oPrev, oNext, hPrev, hNext) {\n        this.key = key;\n        this.value = value;\n        this.oPrev = oPrev;\n        this.oNext = oNext;\n        this.hPrev = hPrev;\n        this.hNext = hNext;\n    }\n}\n\n/**\n * This is a Least Recently Used Cache. It's used to keep a minimal\n * storage of a pool of recently used data. It removes the least\n * recently used entry if the pool overfills. This is useful in OS,\n * but I think it's great for a simple way of preventing over caching \n * too much information.\n * \n * DESIGN\n * The design of this LRU cache is simple. It uses a simple linked\n * hash map. The oject keys need to have 1 parameter and 1 field,\n * the hashCode field and the equals() function. The hash map is\n * great for checking if an entry exists O(1) time. Within the hasmap\n * through is also a linked list. This doubly linked list connects\n * all stored nodes and has 2 dummy nodes at the start and end.\n * \n * Both the hash map and the linked lists have their own set of\n * nodes in each LRU Node, but the hash map is only a unidirectional\n * linked list. the least recently used linked list is a doubly linked\n * list.\n * \n * The doubly linked list is used to keep track of the usage sequence\n * of stored nodes.\n * \n * \n * This is a Least Recently Used Cache (LRU Cache) implementation.\n * This is used for storing the most important search results. This\n * isn't absolutely necessary for a client side approach, since\n * the client probably won't generate hundreds of thousands of\n * search queries. So, this is mostly better for server side, but\n * I'm adding this anyways.\n * \n * An LRU cache is implemented with a hash table and the hash table\n * contains double linked list pointers (e.g. can go forward and\n * backward).\n * \n * Also, another thing to note. Since our key is a compound key, and\n * we generated our own hash value. We need to be careful of collisions,\n * since we can't guarantee the key we used to insert into the Map is\n * unique.\n * \n * There are 2 approaches that I can think of for this issue.\n *  1) create a Map object, but store all collision entries in an\n *     array (e.g. buckets. Also called separate chaining)\n *  2) array form but use linear probing to insert entries, but makes\n *     worst case checking O(n) if the size of the array is too small.\n * \n * I'll do separate chaining again, so O(n) worst case search. Just cause\n * I haven't made it so I can rehash the whole table. \n * \n * ASSUMPTIONS: All inputs for the key entry requires the field \n * \"hashCode\" since this class doesn't hash the value itself. It\n * relies on the external class to supply a hash value.\n */\nexport default class LRUCache {\n\n    /**\n     * @param {number} maxsize - The max size of the LRU cache and\n     *                              the size of the hash map.\n     */\n    constructor(maxsize = 20) {\n\n        // Create Nodes to maintain order of access linked list\n        const startDummyNode = new LRUNode(null, null);\n        const endDummyNode = new LRUNode(null, null);\n        startDummyNode.oNext = endDummyNode;\n        endDummyNode.oPrev = startDummyNode;\n\n        // initialize fields\n        this.maxsize = maxsize > 0 ? maxsize : 20;\n        this.size = 0;\n        this.table = Array(maxsize).fill(null);\n        this.start = startDummyNode;\n        this.end = endDummyNode\n\n        // Initializes each array entry to have a node\n        for (let i = 0; i < this.table.length; i++) {\n            this.table[i] = new LRUNode(null, null);\n        }\n\n    }\n\n    /**\n     * This function inserts a value into the LRU cache and stores it.\n     * It will also remove an old entry if it exceeds the maxsize.\n     * \n     * @param {LRUKey} key \n     * @param {Object} value \n     */\n    insert(key, value) {\n        if (key == null || value == null) return;\n\n        // we can assume that the table entry already has an entry.\n        let node = this.table[this.generateHashIndex(key.hashCode)];\n\n        while (node.hNext != null) {\n            node = node.hNext;\n\n            // If the key is already in storage\n            if (node.key.equals(key)) {\n\n                // rotate to front\n                this.removeAndAddToStart(node);\n                return;\n            }\n        }\n\n        // we can now assume node is right before end of list, so insert in\n        const newNode = new LRUNode(key, value);\n\n        // update hash map references\n        node.hNext = newNode;\n        newNode.hPrev = node;\n\n        // update order references\n        this.addToLinkedListHead(newNode);\n    }\n\n    /**\n     * This function is called when either inserting a duplicate\n     * entry found (e.g. we put it at the head of the linked list),\n     * or when we call a retrieve.\n     * @param {LRUNode} node \n     */\n    removeAndAddToStart(node) {\n\n        // If not already at the start\n        if (node.oPrev.key != null) {\n            node.oNext.oPrev = node.oPrev;\n            node.oPrev.oNext = node.oNext;\n            node.oNext = this.start.oNext;\n            node.oPrev = this.start;\n            this.start.oNext.oPrev = node;\n            this.start.oNext = node;\n        }\n\n    }\n\n    /**\n     * This function adds the node to the\n     * head of the access order linked list. \n     * It assumes that the node is not already\n     * in the linked list.\n     * \n     * @param {LRUNode} node \n     */\n    addToLinkedListHead(node) {\n\n        // Increment size\n        this.size++;\n\n        // updates pointers\n        node.oNext = this.start.oNext;\n        node.oPrev = this.start;\n        this.start.oNext.oPrev = node;\n        this.start.oNext = node;\n\n        // checks for overflow\n        if (this.size > this.maxsize) {\n            this.size--;\n\n            // Remove the last node from it's pointers\n            const lastNode = this.end.oPrev;\n\n            // updates ordered linked list\n            lastNode.oPrev.oNext = lastNode.oNext;\n            lastNode.oNext.oPrev = lastNode.oPrev;\n\n            // updates hash map linked list\n            lastNode.hPrev.hNext = lastNode.hNext;\n            if (lastNode.hNext != null) { // hash map linked list only has 1 dummy node, so can't assume next one has.\n                lastNode.hNext.hPrev = lastNode.hPrev;\n            }\n\n        }\n\n    }\n\n    /**\n     * This function checks if the given key exists in the \n     * map.\n     * \n     * @param {LRUKey} key \n     */\n    has(key) {\n        if (key == null) {\n            return false;\n        }\n\n        let node = this.table[this.generateHashIndex(key.hashCode)];\n        while (node.hNext != null) {\n            node = node.hNext;\n\n            if (node.key.equals(key)) {\n                return true;\n            }\n        }\n\n        return node.key != null ? key.equals(node.key) : false;\n    }\n\n    /**\n     * This function returns the stored cache information mapped to the\n     * key object.\n     * \n     * @param {LRUKey} key \n     * @returns \n     */\n    retrieve(key) {\n        \n        if (key == null) {\n            return null;\n        }\n\n        let node = this.table[this.generateHashIndex(key.hashCode)];\n\n        while (node.hNext != null) {\n            node = node.hNext;\n\n            if (node.key.equals(key)) {\n                this.removeAndAddToStart(node);\n                return node.value;\n            }\n        }\n        return null;\n    }\n\n\n    /**\n     * Since we have our own built in\n     * hash table, we need to map the\n     * bins to their corresponding \n     * \n     * @param {number} hashCode \n     */\n    generateHashIndex(hashCode) {\n        return hashCode % this.maxsize;\n    }\n\n\n}","import LRUCache from \"./lru_cache\";\n\n/**\n * These functions are mutators. They don't\n * return anything. They just mutate the passed\n * in array. \n * \n * It assumes x is an array.\n * \n * It assumes ascending is boolean.\n */\nconst sortFunctions = {\n    \"bestMatch\": function (x, ascending = true, keyword = \"potato\") {\n\n        // Some error we need to worry about. Sort best by keyword\n        // doesn't work if there is no keyword. We need this function\n        // to have a default functionality if there is no keyword\n        // passed in. (e.g. keyword = \"\"). You can't sort this at all\n        // so we'll do it by title. \n\n        if (keyword !== \"\") {\n            x.sort(function (a, b) {\n                // This function sucks. This iterates through the whole\n                // post to hopefully find matching key words.\n\n                // So we'll need to traverse the post content. The content is\n                // a nested tree stored in the \"pages\" field. It can take on\n                // the following structure\n                //\n                //  pages: [\n                //      {\n                //          content: \"string to parse\",\n                //          sections: [\n                //              {\n                //                  content: \"content stuff or image file name\",\n                //                  alt-text: \"alternate image text\"\n                //              },\n                //              {\n                //                  content: \"drop down list\",\n                //                  sections: [\n                //                      {\n                //                          content: \"this is nested\"    \n                //                      }, ...\n                //                  ]\n                //              },\n                //              {\n                //                  sections: [\n                //                      {\n                //                          content: \"code here\"\n                //                      },...\n                //                  ]\n                //              }\n                //          ]\n                //      },\n                //      ...\n                //  ]\n                //\n                // The content can be nested an infinite amount of times, but in general\n                // unless some wacko decides to put a drop down in a drop down in a drop down,\n                // normal case should be safe to assume depth of 3 at most for most posts.\n                // \n                // - The pages object is the root element containing all nested children.\n                // - The sections field are optional fields that are guaranteed on the\n                //      first depth of the pages object. On first depth, sections contains\n                //      the primary elements displayed. On second or later depths, they\n                //      contain object type specific content that is dependent on the rendered type.\n                //      not all objects within the first depth can guarantee sections content.\n                // - content field is OPTIONAL and the only field that the regex search should be performed on.\n\n                // Can optimize to cache these expensive operations.\n                const aHit = sortFunctions.stringHitCount(keyword, a);\n                const bHit = sortFunctions.stringHitCount(keyword, b);\n\n                return bHit - aHit;\n\n\n            });\n            return x;\n\n        } else { // if no valid keyword posted in, sort by date uploaded.\n            // copy pased code from the \"datePosted\" function for default behavior\n            x.sort(function (a, b) {\n                const dateA = Date.parse(a.created);\n                const dateB = Date.parse(b.created);\n\n                if (dateA < dateB) {\n                    return -1 * (ascending ? 1 : -1);\n                } else if (dateB < dateA) {\n                    return 1 * (ascending ? 1 : -1);\n                } else {\n                    return 0;\n                }\n            });\n\n            return x;\n        }\n    },\n    \"title\": function (x, ascending = true, keyword = \"potato\") {\n        x.sort(function (a, b) {\n            return a.title.localeCompare(b.title) * (ascending ? 1 : -1);\n        });\n\n        return x;\n    },\n    \"datePosted\": function (x, ascending = true, keyword = \"potato\") {\n        x.sort(function (a, b) {\n            const dateA = Date.parse(a.created);\n            const dateB = Date.parse(b.created);\n\n            if (dateA < dateB) {\n                return -1 * (ascending ? 1 : -1);\n            } else if (dateB < dateA) {\n                return 1 * (ascending ? 1 : -1);\n            } else {\n                return 0;\n            }\n        });\n\n        return x;\n    },\n    \"lastEdited\": function (x, ascending = true, keyword = \"potato\") {\n        x.sort(function (a, b) {\n            const dateA = Date.parse(a.updated);\n            const dateB = Date.parse(b.updated);\n\n            if (dateA < dateB) {\n                return -1 * (ascending ? 1 : -1);\n            } else if (dateB < dateA) {\n                return 1 * (ascending ? 1 : -1);\n            } else {\n                return 0;\n            }\n        });\n\n        return x;\n    },\n    stringHitCount: function (searchStr, postObject) {\n\n        /**\n         * This function uses a regex expression to iterate through\n         * and search for matching cases.\n         */\n        const regexExpression = new RegExp(searchStr.replace(/ +/g, \"|\"), \"gi\");\n        let hit = 0;\n\n        // check the title and description of the post\n        hit += ((postObject[\"title\"] || \"\").match(regexExpression) || []).length;\n\n        hit += ((postObject[\"description\"] || \"\").match(regexExpression) || []).length;\n\n        // Iterate through all post pages\n        for (let index in postObject.pages) {\n            const postElement = postObject.pages[index];\n            // need to recursively DFS check if any hits\n            hit += this.dfsCheckContent(regexExpression, postElement);\n        }\n\n        return hit;\n\n    },\n    dfsCheckContent(regexExp, postElement) {\n        if (postElement == null) {\n            return 0;\n        }\n\n        let count = 0;\n\n        if (Object.hasOwn(postElement, 'content')) {\n            count += ((postElement['content'] || \"\").match(regexExp) || []).length;\n        }\n\n        if (Object.hasOwn(postElement, 'sections')) {\n            for (let nestedPostEl in postElement['sections']) {\n                count += this.dfsCheckContent(regexExp, nestedPostEl);\n            }\n        }\n\n        return count;\n    }\n};\n\n\n/**\n * This class manages storing, organizing, and caching\n * search information given a pool of all available posts.\n * This class assumes a pool of unfiltered posts will be \n * given to it on initialization. \n * \n * This class is intended to be stored in the web worker\n * and used mostly for generating queries. \n * \n * Groupings\n *      type - the main focus of the \n *          tutorial\n *          project\n *          tool\n *          game\n *          other\n *          * should be generated through content\n *      tags - these are more general descriptors for the content\n *          intro\n *          advanced\n *          React.js\n *          Redux\n *          Flux\n *          Konvas\n *          Front End\n *          Back End\n *          Full Stack\n *          Data Science\n *          Object Oriented Programming\n *          Fundamentals\n *          Refresher\n *          video game guide\n *          theory\n *          proof\n *          * can be anything, but maybe APIs used might be helpful\n *          * also should be generated by the given content\n *      programming language - the programming language used in the post\n *          none\n *          JavaScript\n *          Python\n *          C++\n *          C\n *          C#\n *          Java\n *          * should also be generated by the given content\n *      publication status\n *          ongoing\n *          completed\n *          not started\n *          cancelled\n *          hiatus\n *      language\n *          English\n *          Japanese\n *          Chinese\n *          French\n *          * I can only read/write in English. I guess I'm doing Duolingo in Japanese and\n *            I did French in middle/high school. However, I sucked at it so probably won't\n *            translate my posts to other languages.\n * \n */\nexport default class PostStorage {\n\n    /**\n     * This function takes in a single Object. This\n     * object contains objects within it each keyed \n     * through a key value starting from 1. \n     * \n     * @param {Object} jsonObjects - posts to be stored and sorted.\n     */\n    constructor(jsonObjects) {\n\n        this.unfilteredPosts = jsonObjects; // store Objects reference in class\n\n        // Grouping\n        //  The following are JavaScript objects. I use objects since these don't\n        //  change all too frequently. Also, I read a post on when to use Map vs Object.\n        //  I use objects since this is a high read low mutation situation after initialization.\n        //  https://stackoverflow.com/questions/66931535/javascript-object-vs-map-set-key-lookup-performance#:~:text=Use%20Maps%20for%20dictionaries%20with%20lots%20of%20different%2C,caching%2C%20hidden%20classes%20with%20fixed%20memory%20layout%20etc.%29\n        this.typeGroups = Object.create(null); // we don't need any of these extra properties offered by \n        this.tagGroups = Object.create(null);   // prototype\n        this.programmingLanguageGroups = Object.create(null);\n        this.publicationStatusGroups = Object.create(null);\n        this.languageGroups = Object.create(null);\n\n        // Initializes default fields that need to be in there.\n        this.typeGroups[\"tutorial\"] = [];\n        this.typeGroups[\"project\"] = [];\n        this.typeGroups[\"tool\"] = [];\n        this.typeGroups[\"other\"] = [];\n        this.publicationStatusGroups[\"completed\"] = [];\n        this.publicationStatusGroups[\"ongoing\"] = [];\n        this.publicationStatusGroups[\"not started\"] = [];\n        this.publicationStatusGroups[\"cancelled\"] = [];\n        this.publicationStatusGroups[\"hiatus\"] = [];\n        this.languageGroups[\"english\"] = [];\n\n        // This function iterates through and creates groupings.\n        for (let key in jsonObjects) {\n            const obj = jsonObjects[key];   // get object reference\n\n            // Registers it with typeGroups\n            const ty_lc = obj.type.toLowerCase(); // converts to lower case\n            if (ty_lc in this.typeGroups) {\n                this.typeGroups[ty_lc].push(key);\n            } else {\n                this.typeGroups[ty_lc] = [key];\n            }\n\n            // Registers it with tagGroups\n            for (let index in obj.tags) {\n                const t_lc = obj.tags[index].toLowerCase(); // lowercase converted\n\n                if (t_lc in this.tagGroups) {\n                    this.tagGroups[t_lc].push(key);\n                } else {\n                    this.tagGroups[t_lc] = [key];\n                }\n            }\n\n            // Registers it with programmingLanguageGroups\n            for (let index in obj.programming_languages) {\n                const pl_lc = obj.programming_languages[index].toLowerCase(); // lowercase converted\n\n                if (pl_lc in this.programmingLanguageGroups) {\n                    this.programmingLanguageGroups[pl_lc].push(key);\n                } else {\n                    this.programmingLanguageGroups[pl_lc] = [key];\n                }\n            }\n\n            // Registers it with publicationStatusGroup\n            const s_lc = obj.status.toLowerCase();\n            if (s_lc in this.publicationStatusGroups) {\n                this.publicationStatusGroups[s_lc].push(key);\n            } else {\n                this.publicationStatusGroups[s_lc] = [key];\n            }\n\n            // Registers it with languageGroups\n            const lg_lc = obj.language.toLowerCase();\n            if (lg_lc in this.languageGroups) {\n                this.languageGroups[lg_lc].push(key);\n            } else {\n                this.languageGroups[lg_lc] = [key];\n            }\n\n        }\n\n        // Sorts and organizes the data\n        //  definitely not efficient, but if we have\n        //  this run by a web agent. We can have this\n        //  process run in the background.\n        //\n        //  In general though, you want this process running\n        //  on the server at probably consistent intervals to\n        //  keep all data up to date. This is a heafty operation,\n        //  but it should keep the amount of in search processing\n        //  to a minimum.\n        for (let key in this.typeGroups) {\n            this.typeGroups[key].sort();\n        }\n\n        for (let key in this.tagGroups) {\n            this.tagGroups[key].sort();\n        }\n\n        for (let key in this.programmingLanguageGroups) {\n            this.programmingLanguageGroups[key].sort();\n        }\n\n        for (let key in this.publicationStatusGroups) {\n            this.publicationStatusGroups[key].sort();\n        }\n\n        for (let key in this.languageGroups) {\n            this.languageGroups[key].sort();\n        }\n\n        // Prepares Caching Bins\n        this.intersectionCache = new LRUCache(20); // stores merged union of sorted data sets.\n\n        /**\n         * Caching information post note\n         * \n         * There is only 1 cache in this storage, since message passing between\n         * web workers is expensive. I'm caching completed search results external\n         * to this class. Only intermediate value information gets cached here.\n         */\n\n    }\n\n    /**\n     * This function returns a 2D array of string values\n     * storing all the tags in the current dataset. This \n     * is used for generating the tag listings for the\n     * advanced search in the advanced search page.\n     * This should be called right after initialization\n     * since I can't return a value in the constructor,\n     * this is meant to be passed back immediately through\n     * the web worker. The values in the arrays are copied\n     * to avoid destroying the groups upon message back.\n     * \n     * @returns {string[][]} tagArray\n     */\n    getTags() {\n\n\n        return [\n            [...Object.keys(this.typeGroups)],\n            [...Object.keys(this.tagGroups)],\n            [...Object.keys(this.programmingLanguageGroups)],\n            [...Object.keys(this.publicationStatusGroups)],\n            [...Object.keys(this.languageGroups)]\n        ];\n    }\n\n    /**\n     * This function checks the cache for a pre-generated search data. There are\n     * 2 caches that it checks, before generating the data from scratch. It then\n     * returns the completed search result as an array for rendering.\n     * \n     * @param {SearchInput} searchObject - This object contains all search parameters\n     *                                      passed in by the user. This parameter\n     *                                      REQUIRES a SearchInput object. The web worker\n     *                                      needs to convert back the passed in values to\n     *                                      work properly.\n     */\n    search(searchObject) {\n\n        /**\n         * WARNING: Terrible coding practices ahead.\n         * \n         * Okay, so I admit I did something completely devoid of logic.\n         * I decided to use an array to store the intersected data, but I\n         * thought. WOW, JavaScripts lets me store whatever I want in the\n         * array, unlike Java. So I decided to mutate the array. Turns out,\n         * I also cached the mutated array and now it's fucking everything\n         * up. Several tests later, and I finally come back to this abomindation\n         * of code. \n         * \n         * FML.\n         */\n\n        // Part 1 - Check intersection cache for partially completed result\n        let intersectedData = this.intersectionCache.retrieve(searchObject.categoryGroup);\n\n        // If no merged data set is found, then generate it and store it in LRU Cache\n        if (intersectedData == null) {\n\n            intersectedData = this.generateIntersectionData(searchObject.categoryGroup);\n            this.intersectionCache.insert(searchObject.categoryGroup, [...intersectedData]);\n        } else {\n            intersectedData = [...intersectedData]; // due to error mentioned above\n        }\n\n        // Part 2 - Convert Key Dataset to posts\n        //  The previous steps generated an array of key values for the posts,\n        //  but we'll need to store the posts based on the metadata information.\n\n        // This iteration replaces all previous entries with the raw object information.\n        for (let i = 0; i < intersectedData.length; i++) {\n            intersectedData[i] = this.unfilteredPosts[intersectedData[i]];\n        }\n\n        // Part 3 - Sorting\n\n        // Sorting is probably gonna be a crap fest. There are 5 sort methods\n        // and we'll need to do them both ways, so 10 different sort methods.\n        // They are as follows\n        //      1) Most matches (given the keyword, which post has the most matches)\n        //      2) title (sorted by title order)\n        //      3) date posted (when the original post was made)\n        //      4) last edited (when the post was last edited, if at all)\n        //      5) author (nvm, we're not doing this. Only if you had a server full of posts, maybe. But not here.)\n\n        // So we're given a string that says the sort order we'll use. We could use\n        // a switch, but that is O(n) worst cast time complexity to find the right\n        // formula. We might as well use a hash map in this case as well, since this\n        // is a functional programming language (e.g. functions are first class citizens).\n        // we can store a function as a lambda function and call it in the hash map.\n        // Actually, you'd do this in Python. Since this is JavaScript, we can just\n        // have the string call directly a function stored in an object (which is\n        // also a hashMap... I think...)\n\n        // If a valid search method was passed in\n        if (Object.hasOwn(sortFunctions, searchObject.sortBy)) {\n            sortFunctions[searchObject.sortBy](intersectedData, searchObject.ascending, searchObject.keyword);\n\n        } else { // Invalid search results in default behavior of sort by date posted\n            console.error(\"Invalid sort function passed in. Default sort by title.\");\n            sortFunctions[\"datePosted\"](intersectedData, searchObject.ascending, searchObject.keyword);\n        }\n\n        // Part 4 - Filtering\n        // I am stumped. \n        // Okay, so keywords the user enters into the search bar are NOT necessary for most sorts.\n        // sort by date and sort by title don't require the keywords, they filter the output\n        // for it. \n        // Sort by best match requires the keywords, so the keyword is used.\n\n        // In general, if this had a server client, then it's generally not a good idea to\n        // send the user extra post data. However, users might change their keyword search\n        // so the UI would handle that instead of the server, so it might be better to\n        // send a little more extra data the UI handles instead. Although, I guess this\n        // is a static webpage, so I don't really need to worry about this type of interaction.\n        // However, sorting and filtering are expensive. Sorting is O(n log(n)), but with\n        // sort by best match. It's probably O((nm) log (nm)) where m is the max size of\n        // a post, since we'll need to parse the posts using regex expressions. This\n        // might make searching on this static webpage REALLY REALLY slow. I was thinking\n        // that it might be best to cache the result inbetween the Sort and Filter stages\n        // (step 3 and step 4), but then that requires a new intermediate class and I'll\n        // need a way to handle sort by best match independent of this implementation.\n        // The reason for that is because search_input.js hashes the key value on initialization\n        // alongside the search keywords the user input. But, if I wanted to cache the\n        // result inbetween the 2 steps, then I'll need to alter either the class structure\n        // of data alterations or expectations and do something like the category_group.js\n        // where I hash that set of data separately. \n\n        // My brain is burnt. I'm just going to filter this output and cache the result.\n        // RIP. poor foresight has resulted in this. Hopefully typing in the search\n        // bar won't result in too much of a lag spike.\n\n        // This operation is O(nm), where n is the number of posts and m is the max\n        // size of a post or whatever the regex time to parse a post is. Honestly\n        // not sure how efficient regex expressions are so I call them m. However,\n        // maybe it's a little too excessive to parse the whole post. Maybe I can\n        // create a system for a better cache inbetween search and result?\n\n        // Fuck, gotta stop overthinking this. I've been here for 5-7 hours just\n        // pondering on this. Gosh darn it. Time flies when you're sick.\n\n        let filteredDisplayList = []; // This array is the one sent to the UI\n\n        // simple iteration filter.\n        if (searchObject.keyword !== \"\") {\n            for (let index in intersectedData) {\n                const post = intersectedData[index];\n                if (sortFunctions.stringHitCount(searchObject.keyword, post) >= 1) {\n                    filteredDisplayList.push(post);\n                }\n            }\n        } else {\n            filteredDisplayList = intersectedData;\n        }\n\n        // output\n        return filteredDisplayList;\n\n    }\n\n    /**\n     * This function sums together the length of all the 2nd \n     * dimension of the array. E.g.\n     *  [\n     *      [\"1\",\"2\",\"3\"],\n     *      [\"4\",\"5\",\"6\"]\n     *  ]\n     * would return 6.\n     * \n     * This is used for checking if there is a tag\n     * constraint passed in the search input. If there\n     * isn't, then it returns everything.\n     * \n     * An alternative write might be to use either the\n     * reduce function, but you'd have to mash all arrays\n     * together then take it's length. \n     * \n     * @param {string[][]} array \n     */\n    helperGet2dArrayLength(array) {\n        let len = 0;\n        for (let row = 0; row < array.length; row++) {\n            for (let column = 0; column < array[row].length; column++) {\n                len++;\n            }\n        }\n        return len;\n    }\n\n    /**\n     * This function generates the intersection tag data.\n     * \n     * UPDATE\n     * Okay, so the name sucks. I confused this with another\n     * function. So this function does NOT generate ONLY\n     * intersection in the search queries. It handles both\n     * the Intersection and Union of the data sets. It's\n     * mostly responsible for mashing the 2 together.\n     * \n     * DEBUGGING\n     * So to add more detail on what the fuck I was writing\n     * when I made this. It's a helper function that mashes\n     * together all the tags in the inclusion and exclusion\n     * data set and creates a single list.\n     * \n     * @param {CategoryGroup} tagSelections - This object contains tags the user selected.\n     */\n    generateIntersectionData(tagSelections) {\n        // Part 1 - Generate Inclusion Data\n\n        // The tags we have in tagSelections are only the key names of\n        // the actual sorted and grouped entry values. We need to convert\n        // these keys to arrays of post keys.\n\n        // Random Note:\n        //      I'm not sure if is more efficient to generate a 2d array o\n        //      entries to merge, then merge them. Or to just iterate over\n        //      using a hashset and add them. The issue though is the AND\n        //      operation, since it requires it to be in both data sets. It\n        //      would be more difficult since we would need to keep a running\n        //      list of tags that have been touched or not per layer. Maybe\n        //      a hashset of index values that only increment if the previous\n        //      hit occured and we can just iterate through for only the ones\n        //      with the final index value sum. \n\n        // This array is used to store each array of keys\n        let entriesToMerge = [];\n\n        // Iterate through the typeGroup keys\n        for (let index in tagSelections.iTags[0]) {\n            const typeTag = tagSelections.iTags[0][index];\n\n            // add to entries ONLY if it exists \n            if (typeTag in this.typeGroups) {\n                entriesToMerge.push(this.typeGroups[typeTag]);\n            }\n        }\n\n        // Iterate through the tags that are explicitly for tagging data\n        // (apologies for the confusing name. Brain can't handle naming things.)\n        for (let index in tagSelections.iTags[1]) {\n            const tagTag = tagSelections.iTags[1][index];\n            if (tagTag in this.tagGroups) {\n                entriesToMerge.push(this.tagGroups[tagTag]);\n            }\n        }\n\n        // Iterate through programming languages\n        for (let index in tagSelections.iTags[2]) {\n            const pgTag = tagSelections.iTags[2][index];\n            if (pgTag in this.programmingLanguageGroups) {\n                entriesToMerge.push(this.programmingLanguageGroups[pgTag]);\n            }\n        }\n\n        // Iterate through publication status\n        for (let index in tagSelections.iTags[3]) {\n            const psTag = tagSelections.iTags[3][index];\n            if (psTag in this.publicationStatusGroups) {\n                entriesToMerge.push(this.publicationStatusGroups[psTag]);\n            }\n        }\n\n        // Iterate through languages group\n        for (let index in tagSelections.iTags[4]) {\n            const lgTag = tagSelections.iTags[4][index];\n            if (lgTag in this.languageGroups) {\n                entriesToMerge.push(this.languageGroups[lgTag]);\n            }\n        }\n\n        // performs the merge operation between the converted data\n        let inclusionDataset = null;\n\n        // If it has no tag constraints, then add the whole tag pool in\n        if (this.helperGet2dArrayLength(tagSelections.iTags) === 0) {\n            inclusionDataset = Object.keys(this.unfilteredPosts);\n\n            // If it is an intersection tag constraint\n        } else if (tagSelections.iAnd) {\n            inclusionDataset = this.generateIntersection(entriesToMerge);\n\n            // If it is a union tag constraint\n        } else {\n            inclusionDataset = this.generateUnion(entriesToMerge);\n        }\n\n        // Part 2 - Generates the exclude data\n        entriesToMerge = [];    // reusing this, cause might as well.\n\n        // Iterate through the typeGroup keys\n        for (let index in tagSelections.eTags[0]) {\n            const typeTag = tagSelections.eTags[0][index];\n            if (typeTag in this.typeGroups) {\n                entriesToMerge.push(this.typeGroups[typeTag]);\n            }\n        }\n\n        // Iterate through the tags that are explicitly for tagging data\n        // NO APOLOGIES!\n        for (let index in tagSelections.eTags[1]) {\n            const tagTag = tagSelections.eTags[1][index];\n            if (tagTag in this.tagGroups) {\n                entriesToMerge.push(this.tagGroups[tagTag]);\n            }\n        }\n\n        // Iterate through programming languages\n        for (let index in tagSelections.eTags[2]) {\n            const pgTag = tagSelections.eTags[2][index];\n            if (pgTag in this.programmingLanguageGroups) {\n                entriesToMerge.push(this.programmingLanguageGroups[pgTag]);\n            }\n        }\n\n        // Iterate through publication status\n        for (let index in tagSelections.eTags[3]) {\n            const psTag = tagSelections.eTags[3][index];\n            if (psTag in this.publicationStatusGroups) {\n                entriesToMerge.push(this.publicationStatusGroups[psTag]);\n            }\n        }\n\n        // Iterate through languages group\n        for (let index in tagSelections.eTags[4]) {\n            const lgTag = tagSelections.eTags[4][index];\n            if (lgTag in this.languageGroups) {\n                entriesToMerge.push(this.languageGroups[lgTag]);\n            }\n        }\n\n        // performs the merge operation between the converted data\n        let exclusionDataset = null;\n\n        if (tagSelections.eAnd) {\n            exclusionDataset = this.generateIntersection(entriesToMerge);\n        } else {\n            exclusionDataset = this.generateUnion(entriesToMerge);\n        }\n\n        // Part 3 - Filter out excluded data from included data\n        // Note: we can assume that the 2 data sets are alphanumerically\n        // sorted, since the merge preserved sort order. We can simply\n        // iterate through the 2 lists and only insert the ones in\n        // the inclusion list that aren't found in exclusion list.\n        const outputList = [];\n\n        let incI = 0;\n        let excI = 0;\n        while (incI < inclusionDataset.length && excI < exclusionDataset.length) {\n\n            if (inclusionDataset[incI].localeCompare(exclusionDataset[excI]) === -1) { // umatched inclusion tag, insert\n                outputList.push(inclusionDataset[incI]);\n                incI++;\n\n            } else if (inclusionDataset[incI].localeCompare(exclusionDataset[excI]) === 1) { // unmatched exclusion tag\n                excI++;\n\n            } else { // matching entry, so ignore inclusion data set entry and increment both\n                incI++;\n                excI++;\n\n            }\n\n        }\n        // flush inclusion entries if any remain\n        while (incI < inclusionDataset.length) {\n            outputList.push(inclusionDataset[incI]);\n            incI++;\n        }\n\n        return outputList;\n    }\n\n    /**\n     * This function iterates through both\n     * string arrays and performs a union (or)\n     * operation between the 2.\n     * \n     * I was figuring out how to use reduce, but then\n     * I found this post.\n     * https://medium.com/swlh/javascript-reduce-with-examples-570f1b51e854\n     * although I sorted by data to avoid having to use a hash set. This\n     * works as well as an alternative code.\n     * \n     * Note: we can assume that the lists in each string have unique tags.\n     * E.g. they appear only once, so we don't need to worry about duplicates.\n     * \n     * \n     * @param {string[][]} tagList \n     */\n    generateUnion(tagList) {\n        if (tagList.length === 0) {\n            return tagList;\n        }\n\n        return tagList.reduce((prev, curr) => {\n            const output = [];\n            let i = 0;\n            let j = 0;\n\n            while (i < prev.length && j < curr.length) {\n\n\n                if (prev[i].localeCompare(curr[j]) === -1) { // prev comes before curr\n                    output.push(prev[i]);\n                    i++;\n\n                } else if (prev[i].localeCompare(curr[j]) === 1) { // curr comes before prev\n                    output.push(curr[j])\n                    j++;\n\n                } else { // same entry found\n                    output.push(curr[i]);\n                    i++;\n                    j++;\n\n                }\n            }\n\n            while (i < prev.length) {\n                output.push(prev[i]);\n                i++;\n            }\n\n            while (j < prev.length) {\n                output.push(curr[j])\n                j++;\n            }\n\n            return output;\n        });\n        // Medium version\n        //return tagList.reduce((prev, curr) => [...new Set(first.concat(second))]);\n    }\n\n    generateIntersection(tagList) {\n        if (tagList.length === 0) {\n            return [];\n        }\n\n        return tagList.reduce((prev, curr) => {\n            const output = [];\n            let i = 0;\n            let j = 0;\n\n            while (i < prev.length && j < curr.length) {\n\n                if (prev[i].localeCompare(curr[j]) === -1) { // prev comes before curr\n                    i++;\n\n                } else if (prev[i].localeCompare(curr[j]) === 1) { // curr comes before prev\n                    j++;\n\n                } else { // same entry found\n                    output.push(prev[i]);\n                    i += 1;\n                    j += 1;\n\n                }\n            }\n\n            return output;\n        })\n    }\n\n}","/**\n * This is an abstract class used\n * to specify what values are required\n * to be able to use an object as a key\n * to pass it into the LRU Cache.\n */\nexport default class LRUKey{\n    constructor() {\n        this.hashCode = 1;\n    }\n\n    equals(other) {\n        if (other == null) {\n            return false;\n        }\n\n        return this.hashCode === other.hashCode;\n    }\n}","/**\n * Source: https://github.com/bryc/code/blob/master/jshash/experimental/cyrb53.js\n * \n * This code comes from bryc. At least he said anyone can use it on stack overflow\n * https://stackoverflow.com/questions/7616461/generate-a-hash-from-string-in-javascript\n * \n * Anyways, this is a string hash function. There is no special reason I decided to use this\n * hash function. It just seemed convenient. Given our application, we don't need a \n * cryptographic hash function, so security doesn't matter. Mostly just need a hash\n * function focused on speed and some degree of collision resiliance. If you don't\n * want to use this hash function, you can use MD5 instead. I'm not too sure how\n * fast it is, but it's a fair hash function to use in this situation.\n * \n * I'm not too sure why I put this in a separate file. there is no reason to do so, but oh well.\n * I think it might be that this hash function isn't really a post storage function, but\n * it's only use is in there. I'll keep it here for now in case I might use this for something\n * else.\n * \n * @param {string} str \n * @param {number} seed \n * @returns \n */\nexport const cyrb53 = function (str, seed = 0) {\n    let h1 = 0xdeadbeef ^ seed, h2 = 0x41c6ce57 ^ seed;\n    for (let i = 0, ch; i < str.length; i++) {\n        ch = str.charCodeAt(i);\n        h1 = Math.imul(h1 ^ ch, 2654435761);\n        h2 = Math.imul(h2 ^ ch, 1597334677);\n    }\n    h1 = Math.imul(h1 ^ (h1 >>> 16), 2246822507) ^ Math.imul(h2 ^ (h2 >>> 13), 3266489909);\n    h2 = Math.imul(h2 ^ (h2 >>> 16), 2246822507) ^ Math.imul(h1 ^ (h1 >>> 13), 3266489909);\n    return 4294967296 * (2097151 & h2) + (h1 >>> 0);\n};\n\n/**\n * Required: cyr53. You can replace this with any other string hash function like MD5.\n * \n * This function generates a string hash for all entries of the array, then performs\n * a bitwise XOR operation between all entries to return a final concatenated result.\n * \n * This function is useful in unordered data that still needs the same hash value.\n * \n * based off of this: https://jameshfisher.com/2018/01/09/how-to-hash-multiple-values/\n */\nexport const unorderedArrayStringHash = function (array) {\n    let code = 0;\n    for (let index in array) {\n        const tag = array[index];\n        code = code ^ cyrb53(tag);\n    }\n    return code;\n}\n\n/**\n * Required: cyr53. You can replace this with any other string hash function like MD5.\n * \n * This function serializes the array into a string, then uses the string hash function\n * to generate a hash value. \n * \n * This function is useful for data where order matters. Also, to generally prevent\n * collisions between ordered data.\n */\nexport const orderedArrayStringHash = function (array) {\n    const serializedArray = JSON.stringify(array);\n    return cyrb53(serializedArray);\n}\n\n/**\n * I copied this from StackOverflow from https://stackoverflow.com/a/52657929\n * \n * The intention of this function is to create an asynchronous lock till\n * a condition is satisfied.\n * \n * @param {*} conditionFunction \n * @returns \n */\nexport const until = function (conditionFunction) {\n\n    const poll = resolve => {\n        if (conditionFunction()) resolve();\n        else setTimeout(_ => poll(resolve), 400);\n    }\n\n    return new Promise(poll);\n}","import LRUKey from \"./lru_key\";\nimport { orderedArrayStringHash, unorderedArrayStringHash } from \"./utils\";\n/**\n * This class stores the groupings. \n * \n * E.g. the individual tags for maybe a comic reading website. These tags\n * are stored in the format of\n *      tags: [\n *          [\"ongoing\", \"active\"],\n *          [\"potato\"],\n *          [\"english\"]\n *      ]\n * There is some degree of implied groupings for the first dimension (I'm refering\n * to the top most array) for each entry. The second dimension (I'm referring to the\n * array nested) is more of an unordered set.\n *\n * UPDATE: I've come to realize that you should assume that the arrays are organized\n * in sequence of\n *      1) typeGroups\n *      2) tagGroups\n *      3) programmingLanguageGroups\n *      4) publicationStatusGroups\n *      5) languageGroups\n * This ordering is implied and all string[][] require the first dimension\n * array values to come in this order. If it doesn't this program will break.\n * \n * This class encapsulates comparison, hasing, and storing grouped values. \n * \n * Also, this class is immutable.\n * \n * Additional Note: This class doesn't have to store the inclustion tags and\n * exclusion tags as 2D arrays. This can be collapsed to a single array\n * since usually tags won't intersect. However, you'll need to also update\n * post_storage.js to also store everything in a single hashmap then. As\n * far as I can think, introducing the 2d arrays introduce more complexity\n * for no reason. \n */\nexport default class CategoryGroup extends LRUKey {\n    /**\n     * \n     * @param {string[][]} inclusionTags - This is a list of tags included in the grouping.\n     *                                     We can assume that each value in the array are unique\n     *                                     with respect to the first dimension groups.\n     * @param {boolean} inclusionAnd \n     * @param {string[][]} exclusionTags \n     * @param {boolean} exclusionAnd \n     */\n    constructor(inclusionTags, inclusionAnd, exclusionTags, exclusionAnd) {\n        super();\n\n        // Sets the fields\n        this.iTags = inclusionTags;\n        this.iAnd = inclusionAnd;\n        this.eTags = exclusionTags;\n        this.eAnd = exclusionAnd;\n\n        // This was more readable a previous version, but it didn't work cause I didn't\n        // iterate the array properly, so I changed it to this. This is much more painful now.\n        // lol.\n        this.hashCode = orderedArrayStringHash(\n            [\n                this.iTags.map((list) => unorderedArrayStringHash(list)).reduce((acc, next) => {return acc^next}),\n                this.iAnd ? \"T\" : \"F\",\n                this.eTags.map((list) => unorderedArrayStringHash(list)).reduce((acc, next) => {return acc^next}),\n                this.eAnd ? \"T\" : \"F\"\n            ]\n        );\n\n\n        // This might not be the most secure way to hash together a 2D array of strings, but oh well.\n    }\n\n    /**\n     * \n     * @param {CategoryGroup} otherCategoryGroup \n     */\n    equals(otherCategoryGroup) {\n\n        // makes sure other pointer is not null\n        if (otherCategoryGroup == null) {\n            return false;\n        }\n\n        // compares hash codes \n        if (otherCategoryGroup.hashCode !== this.hashCode) {\n            return false;\n        }\n\n        // compares of both inclusionAnd and exclusionAnd properties are the same\n        if ((this.iAnd !== otherCategoryGroup.iAnd) || (this.eAnd !== otherCategoryGroup.eAnd)) {\n            return false;\n        }\n\n        // Compares the inclusion/exclusion array's sizes are the same\n        if (this.iTags.length !== otherCategoryGroup.iTags.length || this.eTags.length !== otherCategoryGroup.eTags.length) {\n            return false;\n        }\n\n        // Compares inclusion tag's lists\n        if (!CategoryGroup.helperCompare2DMatrix(this.iTags, otherCategoryGroup.iTags)) {\n            return false;\n        }\n\n        // compares exclusion tag's lists\n        if (!CategoryGroup.helperCompare2DMatrix(this.eTags, otherCategoryGroup.eTags)) {\n            return false;\n        }\n\n        // if everything checks out.\n        return true;\n    }\n\n    /**\n     * This is a helper function used to compare \n     * the inclusionTags or exclusionTags arrays.\n     * This is used primarily in the compare() function.\n     * \n     * This function assumes arr1 and arr2 are arrays of\n     * unique values (e.g. no duplicate entries) and that\n     * they're unordered. This returns if both arr1 and arr2\n     * have the same string values. \n     * \n     * @param {string[][]} arr1 \n     * @param {string[][]} arr2 \n     */\n    static helperCompare2DMatrix(arr1, arr2) {\n        const tagGroupMap = new Map(); // maps the tag groups in the array\n\n        // populates the map\n        for (let index in arr1) {\n            const tagGroup = arr1[index];\n            const grpHash = unorderedArrayStringHash(tagGroup);\n\n            // If the hash of the tag group already exists, we \n            // can just append duplicate values in the hash map.\n            // otherwise, we just create a new entry in the hash map.\n            if (tagGroupMap.has(grpHash)) {\n                tagGroupMap.get(grpHash).push(tagGroup);\n            } else {\n                tagGroupMap.set(grpHash, [tagGroup]);\n            }\n        }\n\n        // checks the map\n        for (let index in arr2) { // other tag group iteration\n            const oTagGroup = arr2[index];\n            const grpHash = unorderedArrayStringHash(oTagGroup);\n\n            if (!tagGroupMap.has(grpHash)) {\n                return false;\n            }\n\n            // this iterates through the open map entry. If it finds\n            // a matching array to the current other Category Group array,\n            // then return true. Otherwise, keep searching.\n            let foundArray = false;\n            for (let mapEntry in tagGroupMap.get(grpHash)) {\n                if (CategoryGroup.compareUnorderedSets(oTagGroup, mapEntry)) {\n                    foundArray = true;\n                    break;\n                }\n            }\n\n            if (!foundArray) {\n                return false;\n            }\n        }\n\n        return true;\n\n    }\n\n    /**\n     * This is a helper method for comparing if 2 unordered\n     * sets contain the same entries. This is used for comparing\n     * the 2nd dimension sets in the inclusionTags or exclusionTags\n     * arrays.\n     * \n     * This function uses a Set to compare the 2, so it's an O(n)\n     * memory space complexity and O(n) time complexity.\n     * \n     * @param {string[]} arr1 \n     * @param {string[]} arr2 \n     * @returns \n     */\n    static compareUnorderedSets(arr1, arr2) {\n\n        // Quick exit\n        if (arr1.length !== arr2.length) {\n            return false;\n        }\n\n        const hashMap = new Set();\n\n        for (let entry in arr1) {\n            hashMap.add(entry);\n        }\n\n        for (let entry in arr2) {\n            if (!hashMap.has(entry)) {\n                return false;\n            }\n        }\n\n        return true;\n    }\n\n    get copy() {\n        const iTagsCopy = [];\n        const eTagsCopy = [];\n\n        for (let group in this.iTags) {\n            iTagsCopy.push([...group]);\n        }\n\n        for (let group in this.eTags) {\n            eTagsCopy.push([...group]);\n        }\n\n        return new CategoryGroup(iTagsCopy, this.inclusionAnd, eTagsCopy, this.exclusionAnd);\n    }\n\n}","import CategoryGroup from \"./category_group\";\nimport LRUKey from \"./lru_key\";\nimport { orderedArrayStringHash } from \"./utils\";\n\n/**\n * This class is a search input. \n * This stores a single search result.\n * The values are not meant to be mutated\n * once created. This is more of designed\n * like a package that doesn't change once\n * passed in from the UI. It's also meant\n * to be a key wrapper, since hashes aren't\n * perfect. This stores the original key and\n * hashes of it.\n * \n * Also, this class is immutable.\n */\nexport default class SearchInput extends LRUKey {\n\n    /**\n     * \n     * @param {string} keyword - the keyword the user searched by.\n     * @param {string} sortBy \n     * @param {boolean} ascending \n     * @param {string[][]} inclusionTags \n     * @param {boolean} inclusionAnd \n     * @param {string[][]} exclusionTags \n     * @param {boolean} exclusionAnd \n     */\n    constructor(keyword, sortBy, ascending, inclusionTags, inclusionAnd, exclusionTags, exclusionAnd) {\n        super();\n\n        // Initializes fields\n        this.keyword = keyword;\n        this.sortBy = sortBy;\n        this.ascending = ascending;\n\n        // Generates the Category Group\n        this.categoryGroup = new CategoryGroup(inclusionTags, inclusionAnd, exclusionTags, exclusionAnd);\n\n        // Generates the hash code\n        this.hashCode = orderedArrayStringHash([this.keyword, this.sortBy, this.ascending ? \"T\" : \"F\", this.categoryGroup.hashCode]);\n    }\n\n    equals(otherSearchInput) {\n        if (otherSearchInput == null) {\n            console.error(\"null comparison\");\n            return false;\n        }\n\n        // compare hash code\n        if (this.hashCode !== otherSearchInput.hashCode) {\n            return false;\n        }\n\n        // compare keyword\n        if (this.keyword !== otherSearchInput.keyword) {\n            return false;\n        }\n\n        // compare sortBy\n        if (this.sortBy !== otherSearchInput.sortBy) {\n            return false;\n        }\n\n        // compare ascending\n        if (this.ascending !== otherSearchInput.ascending) {\n            return false;\n        }\n\n        // compare groupings\n        return this.categoryGroup.equals(otherSearchInput.categoryGroupCopy);\n\n    }\n\n    /**\n     * This function takes an object will the same\n     * fields as a SearchInput, but adds the methods\n     * to prototype. \n     * \n     * The purpose of this is because when we pass\n     * these classes through the web worker. We lose\n     * all functions. This function restores those \n     * function values and allows us to use it like \n     * a class instead of a collection of values.\n     * \n     * @param {Object} reference\n     */\n    static addMethodsToDummy(reference) {\n        return new SearchInput(\n            reference.keyword,\n            reference.sortBy,\n            reference.ascending,\n            reference.categoryGroup.iTags,\n            reference.categoryGroup.iAnd,\n            reference.categoryGroup.eTags,\n            reference.categoryGroup.eAnd\n        );\n    }\n\n}","import PostStorage from \"../state/post_storage\";\nimport SearchInput from \"../state/search_input\";\n/**\n * WEB WORKER NOTES\n * Reference: https://webpack.js.org/guides/web-workers/\n * \n * There are a few tutorials online about creating web workers\n * in react or JavaScript. However, some of them are for just\n * JavaScript (e.g. we don't need to deal with webpack) or\n * just old and outdated solution (e.g. webpack already has\n * a method for creating web workers). As referenced in the\n * docs above, if we follow webpack's method for creating\n * web workers, we can easily import all necessary classes\n * and files directly into the web worker. \n * \n * IMPLEMENTATION\n * This web worker handles initialization of the search\n * pool, search function calls, and some LRU caching.\n * \n * Also, just to add a note. We'll be using a lot of self\n * references in this implementation, due to me storing\n * some fields in the thread's global state. \n */\n\n/**\n * Global fields for the web worker. We can assume\n * that the initialization will come first, and that\n * will trigger the self.initialized field.\n */\n// eslint-disable-next-line no-restricted-globals\nself.initialized = false;\n// eslint-disable-next-line no-restricted-globals\nself.postStore = null;\n\n/**\n * This is the primary web worker thread. It's\n * a single event caller that will run all passed\n * in actions in a queue.\n * \n * @param {Object} param0 \n */\n// eslint-disable-next-line no-restricted-globals\nself.onmessage = (message) => {\n\n    /**\n     * Initialization Sequence. Registers all JSON objects\n     * into the pool.\n     */\n    // eslint-disable-next-line no-restricted-globals\n    if (!self.initialized) {\n\n        // eslint-disable-next-line no-restricted-globals\n        self.initialized = true;\n        // eslint-disable-next-line no-restricted-globals\n        self.postStore = new PostStorage(message.data);\n\n        // eslint-disable-next-line no-restricted-globals\n        postMessage(self.postStore.getTags()); // returns the generated tag groups\n\n        /**\n         * Search Query Process. Will return the corresponding post information.\n         */\n    } else {\n\n        // Note: we needed to convert the passed in object, since passing\n        // objects copy their field, but lose their methods.\n\n        // eslint-disable-next-line no-restricted-globals\n        const result = self.postStore.search(SearchInput.addMethodsToDummy(message.data));\n\n        // eslint-disable-next-line no-restricted-globals\n        postMessage({key: message.data, value: result});\n    }\n\n};"],"names":["LRUNode","constructor","key","value","oPrev","oNext","hPrev","hNext","this","LRUCache","maxsize","arguments","length","undefined","startDummyNode","endDummyNode","size","table","Array","fill","start","end","i","insert","node","generateHashIndex","hashCode","equals","removeAndAddToStart","newNode","addToLinkedListHead","lastNode","has","retrieve","sortFunctions","x","ascending","keyword","sort","a","b","aHit","stringHitCount","dateA","Date","parse","created","dateB","title","localeCompare","updated","searchStr","postObject","regexExpression","RegExp","replace","hit","match","index","pages","postElement","dfsCheckContent","regexExp","count","Object","hasOwn","nestedPostEl","PostStorage","jsonObjects","unfilteredPosts","typeGroups","create","tagGroups","programmingLanguageGroups","publicationStatusGroups","languageGroups","obj","ty_lc","type","toLowerCase","push","tags","t_lc","programming_languages","pl_lc","s_lc","status","lg_lc","language","intersectionCache","getTags","keys","search","searchObject","intersectedData","categoryGroup","generateIntersectionData","sortBy","console","error","filteredDisplayList","post","helperGet2dArrayLength","array","len","row","column","tagSelections","entriesToMerge","iTags","typeTag","tagTag","pgTag","psTag","lgTag","inclusionDataset","iAnd","generateIntersection","generateUnion","eTags","exclusionDataset","eAnd","outputList","incI","excI","tagList","reduce","prev","curr","output","j","LRUKey","other","cyrb53","str","seed","h1","h2","ch","charCodeAt","Math","imul","unorderedArrayStringHash","code","tag","orderedArrayStringHash","serializedArray","JSON","stringify","CategoryGroup","inclusionTags","inclusionAnd","exclusionTags","exclusionAnd","super","map","list","acc","next","otherCategoryGroup","helperCompare2DMatrix","arr1","arr2","tagGroupMap","Map","tagGroup","grpHash","get","set","oTagGroup","foundArray","mapEntry","compareUnorderedSets","hashMap","Set","entry","add","copy","iTagsCopy","eTagsCopy","group","SearchInput","otherSearchInput","categoryGroupCopy","addMethodsToDummy","reference","self","initialized","postStore","onmessage","message","result","data","postMessage"],"sourceRoot":""}